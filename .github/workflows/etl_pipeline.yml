name: ETL Pipeline - Generate, Upload & Deploy

# Triggers
on:
  push:
    branches: [ main ]
  workflow_dispatch:
  schedule:
    - cron: '0 1 * * *'   # Daily at 1 AM UTC

jobs:
  generate-and-upload:
    name: Generate CSVs, Upload to S3, Deploy Lambda & RDS
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout repository
    - name: 1.1 Checkout repository
      uses: actions/checkout@v4

    # Step 2: Setup Python
    - name: 1.2 Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    # Step 3: Install dependencies
    - name: 1.3 Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libpq-dev gcc postgresql-client
        python -m pip install --upgrade pip
        pip install faker pandas boto3 awscli psycopg2-binary

    # Step 4: Debug environment
    - name: 1.4 Debug environment
      run: |
        python --version
        aws --version
        psql --version
        ls -R

    # Step 5: Run data generator
    - name: 1.5 Generate 90-days sales CSVs
      run: python data_generator/generate_3months_data.py

    # Step 6: Verify generated files
    - name: 1.6 List generated CSV files
      run: |
        echo "Listing CSV files:"
        find sample_data -type f -name "*.csv" -print || true
        echo "Total files:"
        find sample_data -type f -name "*.csv"*_
